{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMi9fmxTzVGeM+I3pprNQ0S",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SalvatoreAdalberto/mlapp/blob/main/LAB8.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iZCLJGoPeb3o"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "R7eiLDIpnmDa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class PositionalEncoding(tf.keras.layers.Layer):\n",
        "  def __init__(self, length, channels) -> None:\n",
        "    super(PositionalEncoding, self).__init__()\n",
        "    self.l = length\n",
        "    self.f = channels\n",
        "  \n",
        "  def get_angles(self, pos, i, d_model):\n",
        "    angle_rates = 1/np.power(10000, (2*(i//2))/np.float32(d_model))\n",
        "    return pos * angle_rates\n",
        "  \n",
        "  def call(self, x):\n",
        "    angle_rads = self.get_angles(np.arange(self.l)[:, np.newaxis],\n",
        "                            np.arange(self.f)[np.newaxis, :],\n",
        "                            self.f)\n",
        "\n",
        "    # apply sin to even indices in the array; 2i\n",
        "    angle_rads[:, 0::2] = np.sin(angle_rads[:, 0::2])\n",
        "\n",
        "    # apply cos to odd indices in the array; 2i+1\n",
        "    angle_rads[:, 1::2] = np.cos(angle_rads[:, 1::2])\n",
        "\n",
        "    pos_encoding = tf.cast(angle_rads[np.newaxis, ...], dtype=tf.float32)\n",
        "\n",
        "    return pos_encoding + x"
      ],
      "metadata": {
        "id": "Xj54M89IoDay"
      },
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pe = PositionalEncoding(100, 10)\n",
        "pe.call()"
      ],
      "metadata": {
        "id": "u0qQTbZ8p1Jw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class AttentionLayer(tf.keras.layers.Layer):\n",
        "  def __init__(self, dim) -> None:\n",
        "    super(AttentionLayer, self).__init__()\n",
        "    self.dense_layers = [tf.keras.layers.Dense(dim, use_bias=False) for _ in range(3)]\n",
        "\n",
        "\n",
        "  def call(self, x):\n",
        "    q, k,v = (dense(x) for dense in self.dense_layers)\n",
        "    qk = tf.linalg.matmul(q, k, transpose_b=True)\n",
        "    dk = tf.cast(tf.shape(k)[-1], tf.float32)\n",
        "    scaled_logits = qk / tf.math.sqrt(dk)\n",
        "    weights = tf.nn.softmax(scaled_logits, axis=-1)\n",
        "\n",
        "    out = tf.linalg.matmul(weights, v)\n",
        "\n",
        "    \n",
        "    return out"
      ],
      "metadata": {
        "id": "wYaHnFTdgnB9"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x = np.random.rand(1, 100, 10)\n",
        "a = AttentionLayer(10)\n",
        "v = a(x)\n",
        "print(v.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BLZJOrL20FUb",
        "outputId": "75b59faf-dfa7-49b6-96c0-67c8af82ae12"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(1, 100, 10)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class TransformerLayer(tf.keras.layers.Layer):\n",
        "  def __init__(self, n_samples, dim) -> None:\n",
        "    super(TransformerLayer, self).__init__()\n",
        "    self.attention = AttentionLayer(dim)\n",
        "    \n",
        "    self.norm1 = tf.keras.layers.Normalization()\n",
        "    self.norm2 = tf.keras.layers.Normalization()\n",
        "    self.feed_forward = tf.keras.layers.Dense(dim)\n",
        "\n",
        "  \n",
        "  def call(self, x):\n",
        "   \n",
        "    y = self.attention(x)\n",
        "    x = self.norm1(y + x)\n",
        "    y = self.feed_forward(x)\n",
        "    x = self.norm2(y+x)\n",
        "\n",
        "    return x\n",
        "    \n",
        "\n",
        "class Transformer(tf.keras.Model):\n",
        "  def __init__(self, n_samples, dim, N) -> None:\n",
        "    super(Transformer, self).__init__()\n",
        "    self.pos_enc = PositionalEncoding(n_samples, dim)\n",
        "    self.tf_layers = [TransformerLayer(n_samples, dim) for _ in range(N)]\n",
        "\n",
        "  def call(self, x):\n",
        "    y = self.pos_enc(x)\n",
        "    for t_layer in self.tf_layers:\n",
        "      y = t_layer(y)\n",
        "    \n",
        "    return y\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "aP4EAYLufedD"
      },
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x = np.random.rand(1, 100, 10)\n",
        "a = Transformer(100, 10, 4)\n",
        "v = a(x)\n",
        "print(v.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "64iNaHEB7v54",
        "outputId": "8471d6cd-2bc4-43db-fca9-e1317592fcae"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(1, 100, 10)\n"
          ]
        }
      ]
    }
  ]
}